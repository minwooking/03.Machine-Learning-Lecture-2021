{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creditcard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    X,y,stratify=y,random_state=0,test_size=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,y_train.shape\n",
    "print('학습 데이터 레이블 값 비율')\n",
    "print(y_train.value_counts()/y_train.shape[0]*100)\n",
    "print('테스트 데이터 레이블 값 비율')\n",
    "print(y_test.value_counts()/y_test.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lr_clf=LogisticRegression()\n",
    "lgbm_clf=LGBMClassifier(n_estimators=1000,num_leaves=64,n_jobs=-1,boost_from_average=False)\n",
    "\n",
    "print('로지스틱 회귀 성능')\n",
    "get_model_train_eval(lr_clf,X_train,X_test,y_train,y_test)\n",
    "print('LightGBM 성능')\n",
    "get_model_train_eval(lgbm_clf, X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train,y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "lr_pred_proba = lr_clf.predict_proba(X_test)[:,-1]\n",
    "\n",
    "# 정확도 , 정밀도 , 재현율  , F1 , AUC 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, y_pred,X_test):\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    F1 = f1_score(y_test, y_pred)\n",
    "    AUC = roc_auc_score(y_test, y_pred)\n",
    "    lr_clf.predict_proba(X_test)[:,-1]\n",
    "    print('오차행렬:\\n', confusion)\n",
    "    print('\\n정확도: {:.4f}'.format(accuracy))\n",
    "    print('정밀도: {:.4f}'.format(precision))\n",
    "    print('재현율: {:.4f}'.format(recall))\n",
    "    print('F1: {:.4f}'.format(F1))\n",
    "    print('AUC: {:.4f}'.format(AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_clf_eval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3edd88dfa71a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_clf_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'get_clf_eval' is not defined"
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_test,lr_pred,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_train_eval(model,ftr_train=None,ftr_test=None,tgt_train=None,tgt_test=None):\n",
    "    model.fit(ftr_train,tgt_train)\n",
    "    pred = model.predict(ftr_test)\n",
    "    pred_proba = model.predict_proba(ftr_test)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train,y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "lr_pred_proba = lr_clf.predict_proba(X_test)[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.xticks(range(0,3000,1000),rotation=60)\n",
    "sns.distplot(df['Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_preprocessed_df(df=None):\n",
    "    df_copy=df.copy()\n",
    "    df_copy.drop('Time',axis=1,inplace=True)\n",
    "    return df_copy\n",
    "\n",
    "def get_train_test_dataset(df=None):\n",
    "    df_copy=get_preprocessed_df(df)\n",
    "    X_features=df_copy.iloc[:,:-1]\n",
    "    y_target=df_copy.iloc[:,-1]\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X_features,y_target,test_size=0.3,random_state=0,stratify=y_target)\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test=get_train_test_dataset(df)\n",
    "\n",
    "print('학습 데이터 레이블 값 비율')\n",
    "print(y_train.value_counts()/y_train.shape[0]*100)\n",
    "print('테스트 데이터 레이블 값 비율')\n",
    "print(y_test.value_counts()/y_test.shape[0]*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score\n",
    "    \n",
    "def get_model_train_eval(model, feature_train=None, feature_test=None, target_train=None, target_test=None):\n",
    "    model.fit(feature_train, target_train)\n",
    "    pred=model.predict(feature_test)\n",
    "    pred_proba=model.predict_proba(feature_test)[:,1]\n",
    "    confusion=confusion_matrix(target_test,pred)\n",
    "    accuracy=accuracy_score(target_test,pred)\n",
    "    precision=precision_score(target_test,pred)\n",
    "    recall=recall_score(target_test,pred)\n",
    "    f1=f1_score(target_test,pred)\n",
    "    roc_auc=roc_auc_score(target_test,pred_proba)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}, AUC: {4:.4f}'.format(accuracy,precision,recall,f1,roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lr_clf=LogisticRegression()\n",
    "lgbm_clf=LGBMClassifier(n_estimators=1000,num_leaves=64,n_jobs=-1,boost_from_average=False)\n",
    "\n",
    "print('로지스틱 회귀 성능')\n",
    "get_model_train_eval(lr_clf,X_train,X_test,y_train,y_test)\n",
    "print('LightGBM 성능')\n",
    "get_model_train_eval(lgbm_clf, X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def get_preprocessed_df(df=None):\n",
    "    df_copy=df.copy()\n",
    "    scaler=StandardScaler()\n",
    "    amount_StandardScaled=scaler.fit_transform(df_copy['Amount'].values.reshape(-1,1))\n",
    "    df_copy.insert(0,'Amount_scaled',amount_StandardScaled)\n",
    "    df_copy.drop(['Time','Amount'],axis=1,inplace=True)\n",
    "    sns.distplot(df_copy['Amount_scaled'])\n",
    "    return df_copy\n",
    "\n",
    "X_train, X_test, y_train, y_test=get_train_test_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lr_clf=LogisticRegression()\n",
    "lgbm_clf=LGBMClassifier(n_estimators=1000,num_leaves=64,n_jobs=-1,boost_from_average=False)\n",
    "\n",
    "print('로지스틱 회귀 성능')\n",
    "get_model_train_eval(lr_clf,X_train,X_test,y_train,y_test)\n",
    "print('LightGBM 성능')\n",
    "get_model_train_eval(lgbm_clf, X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_df(df):\n",
    "    df_copy=df.copy()\n",
    "    amount_log_Scaled=np.log1p(df_copy['Amount'])\n",
    "    df_copy.insert(0,'Amount_Scaled',amount_log_Scaled)\n",
    "    df_copy.drop(['Time','Amount'],axis=1,inplace=True)\n",
    "    sns.distplot(df_copy['Amount_Scaled'])\n",
    "    return df_copy\n",
    "\n",
    "X_train, X_test, y_train, y_test=get_train_test_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf=LogisticRegression()\n",
    "lgbm_clf=LGBMClassifier(n_estimators=1000,num_leaves=64,n_jobs=-1,boost_from_average=False)\n",
    "\n",
    "print('로지스틱 회귀 성능')\n",
    "get_model_train_eval(lr_clf,X_train,X_test,y_train,y_test)\n",
    "print('LightGBM 성능')\n",
    "get_model_train_eval(lgbm_clf, X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "corr=df.corr()\n",
    "sns.heatmap(corr,cmap='RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outlier(df,column,weight=1.5):\n",
    "    fraud=df[df['Class']==1][column]\n",
    "    quantile_25=np.percentile(fraud.values,25)\n",
    "    quantile_75=np.percentile(fraud.values,75)\n",
    "    iqr=quantile_75-quantile_25\n",
    "    iqr_weighted=iqr*weight\n",
    "    lowest_val=quantile_25-iqr_weighted\n",
    "    highest_val=quantile_75+iqr_weighted\n",
    "    outlier_index=fraud[(fraud<lowest_val)|(fraud>highest_val)].index\n",
    "    return outlier_index\n",
    "\n",
    "outlier_index_V14=get_outlier(df,'V14',1.5)\n",
    "print('V14 이상치 데이터 인덱스: ',outlier_index_V14)\n",
    "outlier_index_V17=get_outlier(df,'V17',1.5)\n",
    "print('V17 이상치 데이터 인덱스: ',outlier_index_V17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_df(df):\n",
    "    df_copy=df.copy()\n",
    "    amount_log_Scaled=np.log1p(df_copy['Amount'])\n",
    "    df_copy.insert(0,'Amount_Scaled',amount_log_Scaled)\n",
    "    df_copy.drop(['Time','Amount'],axis=1,inplace=True)\n",
    "    outlier_index_V14=get_outlier(df_copy,'V14',1.5)\n",
    "    df_copy.drop(outlier_index_V14,axis=0,inplace=True)\n",
    "    return df_copy\n",
    "\n",
    "print('V14 이상치 제거')\n",
    "X_train, X_test, y_train, y_test = get_train_test_dataset(df)\n",
    "print('로지스틱 회귀 성능')\n",
    "get_model_train_eval(lr_clf,X_train,X_test,y_train,y_test)\n",
    "print('LightGBM 성능')\n",
    "get_model_train_eval(lgbm_clf, X_train,X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
