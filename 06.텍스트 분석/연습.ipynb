{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- ngram range 를 1,1으로 했을때 count,Tfidf ,  를 svc,dt , rf 로 출력하는 \n",
    "- ngram range 를 1,2으로 했을때 count,Tfidf ,  를 svc,dt , rf 로 출력하는"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC # svc\n",
    "svc = SVC()\n",
    "from sklearn.tree import DecisionTreeClassifier # Dt\n",
    "dt = DecisionTreeClassifier()\n",
    "from sklearn.ensemble import RandomForestClassifier # RF\n",
    "rf = RandomForestClassifier()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         25000 non-null  object\n",
      " 1   sentiment  25000 non-null  int64 \n",
      " 2   review     25000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 586.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "          id  sentiment                                             review\n",
       " 0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       " 1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       " 2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       " 3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       " 4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ...)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/labeledTrainData.tsv',sep='\\t',quoting=3)\n",
    "df.info(),df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review = df.review.str.replace('<br />',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-760429ce98c7>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.review = df.review.str.replace('[^A-Za-z]',' ')\n"
     ]
    }
   ],
   "source": [
    "df.review = df.review.str.replace('[^A-Za-z]',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' With all this stuff going down at the moment with MJ i ve started listening to his music  watching the odd documentary here and there  watched The Wiz and watched Moonwalker again  Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent  Moonwalker is part biography  part feature film which i remember going to see at the cinema when it was originally released  Some of it has subtle messages about MJ s feeling towards the press and also the obvious message of drugs are bad m kay   Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring  Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him   The actual feature film bit when it finally starts is only on for  '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][0][:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train/test dataset 으로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    9375\n",
       " 1    9375\n",
       " Name: sentiment, dtype: int64,\n",
       " 0    3125\n",
       " 1    3125\n",
       " Name: sentiment, dtype: int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    df['review'],df['sentiment'] , stratify= df['sentiment'] , random_state=2021\n",
    ")\n",
    "y_train.value_counts(),y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvect_1 = CountVectorizer(stop_words='english',ngram_range=(1,1))\n",
    "# cvect_1.fit(X_train)\n",
    "# ### 가공 ## \n",
    "# cvect_1.fit(X_train)\n",
    "# X_train_cv_1 = cvect_1.transform(X_train)\n",
    "# X_test_cv_1 = cvect_1.transform(X_test)\n",
    "# tvect_1 = TfidfVectorizer(stop_words='english',ngram_range=(1,2))\n",
    "# tvect_1.fit(X_train)\n",
    "# X_train_tv_1 = tvect_1.transform(X_train)\n",
    "# X_test_tv_1 = tvect_1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_tv_1.shape,X_train_cv_1.shape, X_test_tv_1.shape,X_train_cv_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvect_2 = CountVectorizer(stop_words='english',ngram_range=(1,2))\n",
    "# cvect_2.fit(X_train)\n",
    "# cvect_2.fit(X_train)\n",
    "# X_train_cv_2 = cvect_2.transform(X_train)\n",
    "# X_test_cv_2 = cvect_2.transform(X_test)\n",
    "# tvect_2 = TfidfVectorizer(stop_words='english',ngram_range=(1,2))\n",
    "# tvect_2.fit(X_train)\n",
    "# X_train_tv_2 = tvect_2.transform(X_train)\n",
    "# X_test_tv_2 = tvect_2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_tv_2.shape, X_test_tv_2.shape,X_train_cv_2.shape , X_test_cv_2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time svc.fit(X_train_cv_1,y_train)\n",
    "# %time svc.fit(X_train_cv_2,y_train)\n",
    "# %time dt.fit(X_train_cv_1,y_train)\n",
    "# %time dt.fit(X_train_cv_1,y_train)\n",
    "# %time rf.fit(X_train_cv_1,y_train)\n",
    "# %time rf.fit(X_train_cv_2,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time svc.fit(X_train_tv_1,y_train)\n",
    "# %time svc.fit(X_train_tv_2,y_train)\n",
    "# %time dt.fit(X_train_tv_1,y_train)\n",
    "# %time dt.fit(X_train_tv_1,y_train)\n",
    "# %time rf.fit(X_train_tv_1,y_train)\n",
    "# %time rf.fit(X_train_tv_2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 연습(a,b,c):\n",
    "    globals()[f'{b}_{c}'] = CountVectorizer(stop_words='english',ngram_range=(1,c))\n",
    "    globals()[f'{b}_{c}'].fit(X_train)\n",
    "    globals()[f'X_train_{b}_{c}'] = globals()[f'{b}_{c}'].transform(X_train)\n",
    "    globals()[f'X_test_{b}_{c}'] = globals()[f'{b}_{c}'].transform(X_test)\n",
    "    globals()[f'{a}'].fit(globals()[f'X_train_{b}_{c}'],y_train)\n",
    "    return globals()[f'{a}'].score(globals()[f'X_test_{b}_{c}'],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 연습2(a,b,c):\n",
    "    g= globals()\n",
    "    if b == 'c':\n",
    "        g[f'{b}{c}'] = CountVectorizer(stop_words='english',ngram_range=(1,c))\n",
    "    elif b == 't':\n",
    "        g[f'{b}{c}'] = TfidfVectorizer(stop_words='english',ngram_range=(1,c))\n",
    "    g[f'{b}{c}'].fit(X_train)\n",
    "    g[f'X_train_{b}_{c}'] = g[f'{b}{c}'].transform(X_train)\n",
    "    g[f'X_test_{b}_{c}'] = g[f'{b}{c}'].transform(X_test)\n",
    "    g[f'{a}'].fit(g[f'X_train_{b}_{c}'],y_train)\n",
    "    return g[f'{a}'].score(g[f'X_test_{b}_{c}'],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 연습3(model,vect,i):\n",
    "    g= globals()\n",
    "    if vect == 'cvect':\n",
    "        g[f'{vect}{i}'] = CountVectorizer(stop_words='english',ngram_range=(1,i))\n",
    "    elif vect == 'tvect':\n",
    "        g[f'{vect}{i}'] = TfidfVectorizer(stop_words='english',ngram_range=(1,i))\n",
    "    g[f'{vect}{i}'].fit(X_train)\n",
    "    g[f'X_train_{vect}{i}'] = g[f'{vect}{i}'].transform(X_train)\n",
    "    g[f'X_test_{vect}{i}'] = g[f'{vect}{i}'].transform(X_test)\n",
    "    model.fit(g[f'X_train_{vect}{i}'],y_train)\n",
    "    return model.score(g[f'X_test_{vect}{i}'],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 습작(a,b,c):\n",
    "    g = globals() \n",
    "    vect = g[f'{b}vect_{c}']\n",
    "    XX_train = g()[f'X_train_{b}_{c}']\n",
    "    XX_test = g()[f'X_test_{b}_{c}']\n",
    "    model =  g()[f'{a}']\n",
    "    \n",
    "    if b == 'c':\n",
    "        vect = CountVectorizer(stop_words='english',ngram_range=(1,c))\n",
    "    elif b == 't':\n",
    "        vect = TfidfVectorizer(stop_words='english',ngram_range=(1,c))\n",
    "    vect.fit(X_train)\n",
    "    XX_train = vect.transform(X_train)\n",
    "    XX_test = vect.transform(X_test)\n",
    "    model.fit(XX_train,y_train)\n",
    "    \n",
    "    return model.score(XX_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index in ['svc','dt','rf']:\n",
    "#     for arg in ['c','t']:\n",
    "#             for i in range (1,2):\n",
    "#                     print(연습2(index,arg,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index in [svc,dt,rf]:\n",
    "#     for arg in ['cvect','tvect']:\n",
    "#             for i in range (1,3):\n",
    "#                     print(f'모델:{index}{arg}{i}일때:{연습3(index,arg,i)}입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델:SVC()\t,vect:cvect\tngram_range:1일때:0.87248입니다.\n",
      "모델:SVC()\t,vect:cvect\tngram_range:2일때:0.87504입니다.\n",
      "모델:SVC()\t,vect:tvect\tngram_range:1일때:0.89104입니다.\n",
      "모델:SVC()\t,vect:tvect\tngram_range:2일때:0.8856입니다.\n",
      "모델:DecisionTreeClassifier()\t,vect:cvect\tngram_range:1일때:0.72048입니다.\n",
      "모델:DecisionTreeClassifier()\t,vect:cvect\tngram_range:2일때:0.72784입니다.\n",
      "모델:DecisionTreeClassifier()\t,vect:tvect\tngram_range:1일때:0.71712입니다.\n",
      "모델:DecisionTreeClassifier()\t,vect:tvect\tngram_range:2일때:0.69248입니다.\n",
      "모델:RandomForestClassifier()\t,vect:cvect\tngram_range:1일때:0.85152입니다.\n",
      "모델:RandomForestClassifier()\t,vect:cvect\tngram_range:2일때:0.84752입니다.\n",
      "모델:RandomForestClassifier()\t,vect:tvect\tngram_range:1일때:0.85056입니다.\n",
      "모델:RandomForestClassifier()\t,vect:tvect\tngram_range:2일때:0.85744입니다.\n"
     ]
    }
   ],
   "source": [
    "for model in [svc,dt,rf]:\n",
    "    for vect in ['cvect','tvect']:\n",
    "            for i in [1,2]:\n",
    "                    print(f'모델:{model}\\t,vect:{vect}\\tngram_range:{i}일때:{연습3(model,vect,i)}입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in [svc,dt,rf]:\n",
    "#     for vect in ['cvect','tvect']:\n",
    "#             for i in [1,2]:\n",
    "#                     print(f'모델:{model},vect:{vect}ngram_range:{i}일때:{연습3(model,vect,i)}입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연습(svc,cv,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# cvect_1.fit(X_train)\n",
    "# X_train_cv_1 = cvect_1.transform(X_train)\n",
    "# X_test_cv_1 = cvect_1.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# tvect_1.fit(X_train)\n",
    "# X_train_tv_1 = tvect_1.transform(X_train)\n",
    "# X_test_tv_1 = tvect_1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tvect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "# tvect.fit(X_train)\n",
    "# X_train_tv = tvect.transform(X_train)\n",
    "# X_test_tv = tvect.transform(X_test)\n",
    "# X_train_tv.shape, X_test_tv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvect_2 = CountVectorizer(stop_words='english',ngram_range=(1,2))\n",
    "# cvect_2.fit(X_train)\n",
    "# X_train_cv_2 = cvect_2.transform(X_train)\n",
    "# X_test_cv_2 = cvect_2.transform(X_test)\n",
    "# tvect_2 = TfidfVectorizer(stop_words='english',ngram_range=(1,2))\n",
    "# tvect_2.fit(X_train)\n",
    "# X_train_tv_2 = tvect_2.transform(X_train)\n",
    "# X_test_tv_2 = tvect_2.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
